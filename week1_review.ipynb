{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week1_review.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+x1MvspkjaaMUjiQNNBFN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnnymskang/GANS_melanoma/blob/master/week1_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOQPudUbMc-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c7e6a554-ab74-4943-b7ff-58f08cdcf25c"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install NumPy\n",
        "!pip install sklearn\n",
        "!pip install matplotlib"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: NumPy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbQYDHqyjTfR",
        "colab_type": "text"
      },
      "source": [
        "Note that I've mostly referred and adapted from : https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v_yWl_gVduD",
        "colab_type": "text"
      },
      "source": [
        "1. Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0scAlVfmV5q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUqthcqQV6Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485,) , (0.229,))\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485,) , (0.229,))\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTGOC2L1ZtDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_datasets = {x: datasets.MNIST('PATH_TO_STORE_TRAINSET', train=y,transform=data_transforms[x],download=True) for x, y in {'train':True, 'val':False}.items()}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=1)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPPV7WFFelD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5d813838-0f15-4282-9114-0231e59f8fa6"
      },
      "source": [
        "device,class_names,dataset_sizes"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0),\n",
              " ['0 - zero',\n",
              "  '1 - one',\n",
              "  '2 - two',\n",
              "  '3 - three',\n",
              "  '4 - four',\n",
              "  '5 - five',\n",
              "  '6 - six',\n",
              "  '7 - seven',\n",
              "  '8 - eight',\n",
              "  '9 - nine'],\n",
              " {'train': 60000, 'val': 10000})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I47f3mUleTh5",
        "colab_type": "text"
      },
      "source": [
        "1a. Visualize the data points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNuIukW5eRK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "dbb4e183-18e8-4fa4-c374-85b9aeaec61a"
      },
      "source": [
        "def imshow(inp, title=None, ax=None ):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array(0.485,)\n",
        "    std = np.array(0.229,)\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if ax is None:\n",
        "      fig, ax = plt.subplots(1)\n",
        "    ax.imshow(inp)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    if title is not None:\n",
        "      ax.set_title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs, nrow=2)\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
        "imshow(out, title=[class_names[x] for x in classes], ax=ax)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocl8Z56QVq6i",
        "colab_type": "text"
      },
      "source": [
        "2. NN model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uldpLsN7V9Fg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8ddcf8dd-e74b-4be3-e8a7-32c441007d6f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        #print(\"before maxpool2d, conv1:{}\".format(x.size()))\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        #print(\"After maxpool2d, conv1:{}\".format(x.size()))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        #print(\"After maxpool2d, conv2:{}\".format(x.size()))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        #print(\"Before Relu, fc1:{}\".format(x.size()))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #print(\"Before Relu, fc2:{}\".format(x.size()))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        #print(\"Before Relu, fc3:{}\".format(x.size()))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfRMSUlBV8La",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-D4TkPsVrCP",
        "colab_type": "text"
      },
      "source": [
        "3. Training the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OeKuJWcjnPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Schedule the learning rate and save the best model "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZA9RccoV91X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    model.to(device)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    #print(\"pass\")\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6QJWRFhV9iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "cd0350aa-0d0c-4c65-c6be-12726f6f7b77"
      },
      "source": [
        "model_ft = train_model(net, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.0185 Acc: 0.9946\n",
            "val Loss: 0.0388 Acc: 0.9882\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.0183 Acc: 0.9948\n",
            "val Loss: 0.0369 Acc: 0.9891\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0178 Acc: 0.9947\n",
            "val Loss: 0.0388 Acc: 0.9885\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0153 Acc: 0.9957\n",
            "val Loss: 0.0383 Acc: 0.9885\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0156 Acc: 0.9954\n",
            "val Loss: 0.0386 Acc: 0.9886\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0155 Acc: 0.9958\n",
            "val Loss: 0.0387 Acc: 0.9888\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0150 Acc: 0.9957\n",
            "val Loss: 0.0383 Acc: 0.9885\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0151 Acc: 0.9957\n",
            "val Loss: 0.0381 Acc: 0.9887\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0151 Acc: 0.9960\n",
            "val Loss: 0.0388 Acc: 0.9883\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0157 Acc: 0.9956\n",
            "val Loss: 0.0383 Acc: 0.9884\n",
            "\n",
            "Training complete in 17m 53s\n",
            "Best val Acc: 0.989100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNFDGYRkVu6I",
        "colab_type": "text"
      },
      "source": [
        "4. Testing the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXZKKbyeV-nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHQUPRHYV-eR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2V2hIsWVxtP",
        "colab_type": "text"
      },
      "source": [
        "5. Visualization of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwToF-OsV_ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3VbH6hAV_XO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy6WQoOQVbM9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}